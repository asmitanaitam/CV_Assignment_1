{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image captured and saved.\n",
      "Image captured and saved.\n",
      "Image captured and saved.\n",
      "Image captured and saved.\n",
      "Image captured and saved.\n",
      "Image captured and saved.\n",
      "Image captured and saved.\n",
      "Image captured and saved.\n",
      "Image captured and saved.\n"
     ]
    }
   ],
   "source": [
    "import depthai as dai\n",
    "import cv2\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Create a color camera node and set its properties\n",
    "cam_rgb = pipeline.createColorCamera()\n",
    "cam_rgb.setPreviewSize(640, 480)  # Set preview size to a standard resolution\n",
    "cam_rgb.setInterleaved(False)\n",
    "cam_rgb.setFps(30)  # Set the camera FPS to match the display rate\n",
    "\n",
    "# Create XLinkOut node for the camera preview\n",
    "xout_rgb = pipeline.createXLinkOut()\n",
    "xout_rgb.setStreamName(\"rgb\")\n",
    "cam_rgb.preview.link(xout_rgb.input)\n",
    "\n",
    "# Connect to the device and start the pipeline\n",
    "with dai.Device(pipeline) as device:\n",
    "    # Get output queue\n",
    "    q_rgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "\n",
    "    while True:\n",
    "        in_rgb = q_rgb.tryGet()  # Non-blocking call to get data from the queue\n",
    "        if in_rgb is not None:\n",
    "            frame = in_rgb.getCvFrame()\n",
    "            cv2.imshow(\"RGB\", frame)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('c'):  # Press 'c' to capture and save the image, press 'q' to exit.\n",
    "                cv2.imwrite('captured_image.jpg', frame)\n",
    "                print(\"Image captured and saved.\")\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\\img_1.jpg\n",
      "images\\img_10.jpg\n",
      "images\\img_2.jpg\n",
      "images\\img_3.jpg\n",
      "images\\img_4.jpg\n",
      "images\\img_5.jpg\n",
      "images\\img_6.jpg\n",
      "images\\img_7.jpg\n",
      "images\\img_8.jpg\n",
      "images\\img_9.jpg\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob('images/*.jpg')\n",
    "\n",
    "for image in images:\n",
    "    \n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\\img_1.jpg\n",
      "[]\n",
      "[]\n",
      "images\\img_10.jpg\n",
      "[]\n",
      "[]\n",
      "images\\img_2.jpg\n",
      "[]\n",
      "[]\n",
      "images\\img_3.jpg\n",
      "[]\n",
      "[]\n",
      "images\\img_4.jpg\n",
      "[]\n",
      "[]\n",
      "images\\img_5.jpg\n",
      "[]\n",
      "[]\n",
      "images\\img_6.jpg\n",
      "[]\n",
      "[]\n",
      "images\\img_7.jpg\n",
      "[]\n",
      "[]\n",
      "images\\img_8.jpg\n",
      "[]\n",
      "[]\n",
      "images\\img_9.jpg\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "################ FIND CHESSBOARD CORNERS - OBJECT POINTS AND IMAGE POINTS #############################\n",
    "\n",
    "chessboardSize = (9,9)\n",
    "frameSize = (640,480)\n",
    "\n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "size_of_chessboard_squares_mm = 20\n",
    "objp = objp * size_of_chessboard_squares_mm\n",
    "\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "images = glob.glob('images/*.jpg')\n",
    "\n",
    "for image in images:\n",
    "    \n",
    "    print(image)\n",
    "\n",
    "    img = cv.imread(image)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, chessboardSize, None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, chessboardSize, corners2, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(1000)\n",
    "        \n",
    "        \n",
    "    print(objpoints)\n",
    "    print(imgpoints)\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:3752: error: (-215:Assertion failed) nimages > 0 in function 'cv::calibrateCameraRO'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7a2f1a48d8ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m############## CALIBRATION #######################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcameraMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframeSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cmera Calibrated: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:3752: error: (-215:Assertion failed) nimages > 0 in function 'cv::calibrateCameraRO'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############## CALIBRATION #######################################################\n",
    "\n",
    "ret, cameraMatrix, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, frameSize, None, None)\n",
    "\n",
    "print(\"Cmera Calibrated: \", ret)\n",
    "print(\"\\nCamera Matrix:\\n\", cameraMatrix)\n",
    "print(\"\\nDistortion Parameters:\\n\", dist)\n",
    "print(\"\\n Rotation Vectors:\\n\", rvecs)\n",
    "print(\"\\nTranslation Vectors: \\n\", tvecs)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "#pickle.dump((cameraMatrix, dist), open( \"calibration.pkl\", \"wb\" ))\n",
    "#pickle.dump(cameraMatrix, open( \"cameraMatrix.pkl\", \"wb\" ))\n",
    "#pickle.dump(dist, open( \"dist.pkl\", \"wb\" ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of object points:  0\n",
      "Number of image points:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of object points: \", len(objpoints))\n",
    "print(\"Number of image points: \", len(imgpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2ffaaa4ec2e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cali5.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mnewCameraMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOptimalNewCameraMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcameraMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "############## UNDISTORTION #####################################################\n",
    "\n",
    "img = cv.imread('cali5.png')\n",
    "h,  w = img.shape[:2]\n",
    "newCameraMatrix, roi = cv.getOptimalNewCameraMatrix(cameraMatrix, dist, (w,h), 1, (w,h))\n",
    "\n",
    "\n",
    "\n",
    "# Undistort\n",
    "dst = cv.undistort(img, cameraMatrix, dist, None, newCameraMatrix)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('caliResult1.png', dst)\n",
    "\n",
    "\n",
    "\n",
    "# Undistort with Remapping\n",
    "mapx, mapy = cv.initUndistortRectifyMap(cameraMatrix, dist, None, newCameraMatrix, (w,h), 5)\n",
    "dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('caliResult2.png', dst)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reprojection Error\n",
    "mean_error = 0\n",
    "\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], cameraMatrix, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "\n",
    "print( \"total error: {}\".format(mean_error/len(objpoints)) )\n",
    "print(\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
